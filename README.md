# Realtime AI Backend (WebSockets + Supabase)

## ğŸ“Œ Overview
This project implements a **real-time conversational AI backend** using **FastAPI**, **WebSockets**, **LLM streaming**, and **Supabase (PostgreSQL)**.  
It demonstrates core backend engineering patterns such as:

- Real-time bi-directional communication
- Streaming AI responses with low latency
- Asynchronous data persistence
- Session-based state management
- Post-session automation using background tasks

The project is intentionally built with **minimal UI** to focus on backend architecture and correctness.

---

## ğŸ—ï¸ Architecture Overview

Frontend (HTML + JS)
â”‚
â”‚ WebSocket
â–¼
FastAPI WebSocket Server
â”‚
â”œâ”€â”€ Session State (in-memory)
â”œâ”€â”€ LLM Streaming (OpenAI API)
â”œâ”€â”€ Event Logging (Supabase)
â”‚
â–¼
PostgreSQL (Supabase)
â”‚
â””â”€â”€ Background Task â†’ Session Summary (LLM)

yaml
Copy code

---

## âš™ï¸ Tech Stack

- **Backend Framework**: FastAPI (async)
- **Realtime Communication**: WebSockets
- **LLM Provider**: OpenAI API (streaming responses)
- **Database**: Supabase (PostgreSQL)
- **Environment Management**: python-dotenv
- **Frontend**: Simple HTML + JavaScript

---

## ğŸ“‚ Project Structure

real-time-ai-backend/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI entry point
â”‚ â”œâ”€â”€ websocket.py # WebSocket session handling
â”‚ â”œâ”€â”€ llm.py # LLM streaming logic
â”‚ â”œâ”€â”€ database.py # Supabase client
â”‚ â”œâ”€â”€ background.py # Post-session summarization
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ index.html # Simple WebSocket frontend
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env # Environment variables (not committed)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

pgsql
Copy code

---

## ğŸ—„ï¸ Database Schema (Supabase)

### 1ï¸âƒ£ `sessions` table
```sql
CREATE TABLE sessions (
  session_id TEXT PRIMARY KEY,
  start_time TIMESTAMP,
  end_time TIMESTAMP,
  summary TEXT
);
2ï¸âƒ£ session_events table
sql
Copy code
CREATE TABLE session_events (
  id SERIAL PRIMARY KEY,
  session_id TEXT,
  event_type TEXT,
  content TEXT,
  created_at TIMESTAMP DEFAULT NOW()
);
ğŸš€ Setup Instructions (Windows)
1ï¸âƒ£ Clone the repository
bash
Copy code
git clone https://github.com/Lucky-astro/real-time-ai-backend.git
cd real-time-ai-backend
2ï¸âƒ£ Create and activate virtual environment
bash
Copy code
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Configure environment variables
Create a .env file in the project root:

env
Copy code
OPENAI_API_KEY=your_openai_api_key
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_supabase_anon_or_service_key
âš ï¸ Note: The .env file is intentionally excluded from GitHub.

â–¶ï¸ Running the Application
Start the backend server
bash
Copy code
uvicorn app.main:app --reload
You should see:

nginx
Copy code
Uvicorn running on http://127.0.0.1:8000
Open the frontend
Open the file directly in your browser:

bash
Copy code
frontend/index.html
ğŸ§ª How to Test the System
1ï¸âƒ£ Basic WebSocket Test
Open frontend

Type:

nginx
Copy code
hello
Observe real-time AI response streaming

2ï¸âƒ£ Multi-turn Conversation Test
pgsql
Copy code
My name is Lucky
What is my name?
The AI correctly remembers prior context.

3ï¸âƒ£ Supabase Persistence Test
Check session_events table

Verify user messages are logged with timestamps

4ï¸âƒ£ Post-Session Automation Test
Close or refresh the browser tab

Check sessions table

A concise AI-generated session summary is stored

ğŸ§  Key Design Choices
WebSockets over HTTP: Enables low-latency, bi-directional streaming

Async FastAPI: Non-blocking I/O for scalability

Event-based Persistence: Granular session logging

Graceful Error Handling: AI failures do not crash WebSocket sessions

Minimal Frontend: Focus on backend correctness over UI

âš ï¸ Notes on OpenAI API Usage
OpenAI API requires active billing

If quota is exceeded, the backend:

Handles the error gracefully

Keeps the WebSocket connection alive

This behavior is intentional and production-safe

âœ… Assignment Requirements Mapping
Requirement	Status
WebSocket endpoint	âœ…
Streaming LLM responses	âœ…
Conversation state management	âœ…
Supabase persistence	âœ…
Event logging	âœ…
Post-session summarization	âœ…

ğŸ“Œ Conclusion
This project demonstrates a production-style real-time AI backend with proper async design, state management, persistence, and automation.
It is suitable for internship and junior backend engineering evaluations.

ğŸ‘¤ Author
Lucky (Lakshmikar Dadisetty)
GitHub: https://github.com/Lucky-astro

